{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rileykwok/Food-Classification/blob/master/Food-101%20Challenge.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 4561362814113798606,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14935894484555195388\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3626868472348689977\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 5174106528\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8636718378060507306\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "#from mlxtend.preprocessing import minmax_scaling\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input, BatchNormalization, Multiply, Activation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6462 images belonging to 10 classes.\n",
      "Found 3176 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                 samplewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 samplewise_std_normalization=False,\n",
    "                 zca_whitening=False,\n",
    "                 rotation_range=5,\n",
    "                 width_shift_range=0.05,\n",
    "                 height_shift_range=0.05,\n",
    "                 shear_range=0.2,\n",
    "                 zoom_range=0.2,\n",
    "                 channel_shift_range=0.,\n",
    "                 fill_mode='nearest',\n",
    "                 cval=0.,\n",
    "                 horizontal_flip=True,\n",
    "                 vertical_flip=False,\n",
    "                 rescale=1/255,\n",
    "                validation_split=0.33\n",
    "                                  ) #rescale to [0-1], add zoom range of 0.2x and horizontal flip\n",
    "\n",
    "PATH=\"/home/team/바탕화면/sample_cut\"\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "       seed=13,\n",
    "    class_mode = 'categorical',\n",
    "        target_size=(224,224),\n",
    "        batch_size=64,\n",
    "subset=\"training\")\n",
    "\n",
    "\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "        seed=13,\n",
    "        target_size=(224,224),\n",
    "        batch_size=64,\n",
    "        class_mode = 'categorical',\n",
    "        subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 83s 834ms/step - loss: 2.1169 - accuracy: 0.2080 - val_loss: 1.9074 - val_accuracy: 0.3073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.90738, saving model to model.hdf5\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 83s 829ms/step - loss: 1.6034 - accuracy: 0.3897 - val_loss: 1.4241 - val_accuracy: 0.4948\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.90738 to 1.42414, saving model to model.hdf5\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 82s 823ms/step - loss: 1.3299 - accuracy: 0.5006 - val_loss: 1.4564 - val_accuracy: 0.4284\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.42414\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 83s 826ms/step - loss: 1.2124 - accuracy: 0.5558 - val_loss: 1.1208 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.42414 to 1.12082, saving model to model.hdf5\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 87s 866ms/step - loss: 1.1401 - accuracy: 0.5661 - val_loss: 1.0374 - val_accuracy: 0.5699\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.12082 to 1.03745, saving model to model.hdf5\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 82s 822ms/step - loss: 1.0649 - accuracy: 0.6023 - val_loss: 1.1537 - val_accuracy: 0.5521\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.03745\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 83s 825ms/step - loss: 1.0153 - accuracy: 0.6218 - val_loss: 1.2965 - val_accuracy: 0.5872\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.03745\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 83s 825ms/step - loss: 0.9850 - accuracy: 0.6248 - val_loss: 1.1078 - val_accuracy: 0.6328\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.03745\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 86s 856ms/step - loss: 0.9372 - accuracy: 0.6546 - val_loss: 1.1650 - val_accuracy: 0.5954\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.03745\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 82s 816ms/step - loss: 0.8791 - accuracy: 0.6699 - val_loss: 1.0529 - val_accuracy: 0.6719\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.03745\n",
      "Epoch 11/100\n",
      " 43/100 [===========>..................] - ETA: 46s - loss: 0.8525 - accuracy: 0.6840"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'): \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), strides = 2, padding = 'Same', activation ='relu', input_shape = (224,224,3), kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5), strides = 2, padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512, activation = \"relu\",kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation = \"softmax\",kernel_initializer='he_normal',kernel_regularizer=l2()))\n",
    "\n",
    "    #callbacks\n",
    "    checkpointer = ModelCheckpoint(filepath='model.hdf5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=20, mode='auto')\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, mode='auto')\n",
    "    #stpes_per_epoch = 2250/64\n",
    "    model.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=100,\n",
    "                              validation_data=test_generator,validation_steps=750/64, \n",
    "                              epochs=100, callbacks=[checkpointer, reduceLR, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 112, 112, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 56, 56, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 128)       32896     \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 14, 14, 128)       65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 7, 7, 256)         131328    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 7, 7, 256)         262400    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 712,490\n",
      "Trainable params: 712,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/35 [==============================] - 31s 859ms/step - loss: 2.5595 - accuracy: 0.1008 - val_loss: 2.4068 - val_accuracy: 0.1523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.40683, saving model to model.hdf5\n",
      "Epoch 2/100\n",
      "36/35 [==============================] - 30s 823ms/step - loss: 2.1694 - accuracy: 0.1862 - val_loss: 1.7340 - val_accuracy: 0.2799\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.40683 to 1.73397, saving model to model.hdf5\n",
      "Epoch 3/100\n",
      "36/35 [==============================] - 30s 829ms/step - loss: 1.8495 - accuracy: 0.3025 - val_loss: 1.6690 - val_accuracy: 0.3776\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.73397 to 1.66899, saving model to model.hdf5\n",
      "Epoch 4/100\n",
      "36/35 [==============================] - 30s 824ms/step - loss: 1.6005 - accuracy: 0.4144 - val_loss: 1.6003 - val_accuracy: 0.4049\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.66899 to 1.60025, saving model to model.hdf5\n",
      "Epoch 5/100\n",
      "36/35 [==============================] - 36s 989ms/step - loss: 1.4913 - accuracy: 0.4293 - val_loss: 1.7182 - val_accuracy: 0.4516\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.60025\n",
      "Epoch 6/100\n",
      "36/35 [==============================] - 29s 792ms/step - loss: 1.4494 - accuracy: 0.4561 - val_loss: 1.4928 - val_accuracy: 0.4323\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60025 to 1.49277, saving model to model.hdf5\n",
      "Epoch 7/100\n",
      "36/35 [==============================] - 31s 856ms/step - loss: 1.4086 - accuracy: 0.4622 - val_loss: 1.4106 - val_accuracy: 0.4701\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.49277 to 1.41063, saving model to model.hdf5\n",
      "Epoch 8/100\n",
      "36/35 [==============================] - 30s 845ms/step - loss: 1.3307 - accuracy: 0.4961 - val_loss: 1.3807 - val_accuracy: 0.4596\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.41063 to 1.38071, saving model to model.hdf5\n",
      "Epoch 9/100\n",
      "36/35 [==============================] - 33s 928ms/step - loss: 1.3064 - accuracy: 0.5039 - val_loss: 1.5540 - val_accuracy: 0.4073\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.38071\n",
      "Epoch 10/100\n",
      "36/35 [==============================] - 26s 728ms/step - loss: 1.3203 - accuracy: 0.4813 - val_loss: 1.3705 - val_accuracy: 0.4987\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.38071 to 1.37054, saving model to model.hdf5\n",
      "Epoch 11/100\n",
      "36/35 [==============================] - 31s 862ms/step - loss: 1.2820 - accuracy: 0.5143 - val_loss: 1.1820 - val_accuracy: 0.5430\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.37054 to 1.18198, saving model to model.hdf5\n",
      "Epoch 12/100\n",
      "36/35 [==============================] - 31s 849ms/step - loss: 1.2358 - accuracy: 0.5386 - val_loss: 1.1592 - val_accuracy: 0.5456\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.18198 to 1.15919, saving model to model.hdf5\n",
      "Epoch 13/100\n",
      "36/35 [==============================] - 32s 902ms/step - loss: 1.1586 - accuracy: 0.5452 - val_loss: 1.1483 - val_accuracy: 0.5565\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.15919 to 1.14829, saving model to model.hdf5\n",
      "Epoch 14/100\n",
      "36/35 [==============================] - 27s 754ms/step - loss: 1.2454 - accuracy: 0.5282 - val_loss: 1.4280 - val_accuracy: 0.5326\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.14829\n",
      "Epoch 15/100\n",
      "36/35 [==============================] - 30s 838ms/step - loss: 1.1526 - accuracy: 0.5599 - val_loss: 1.1096 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.14829 to 1.10962, saving model to model.hdf5\n",
      "Epoch 16/100\n",
      "36/35 [==============================] - 30s 831ms/step - loss: 1.1356 - accuracy: 0.5638 - val_loss: 1.2655 - val_accuracy: 0.5456\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.10962\n",
      "Epoch 17/100\n",
      "36/35 [==============================] - 31s 874ms/step - loss: 1.0945 - accuracy: 0.6003 - val_loss: 1.2906 - val_accuracy: 0.6089\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.10962\n",
      "Epoch 18/100\n",
      "36/35 [==============================] - 29s 794ms/step - loss: 1.0482 - accuracy: 0.6081 - val_loss: 1.0135 - val_accuracy: 0.5599\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.10962 to 1.01353, saving model to model.hdf5\n",
      "Epoch 19/100\n",
      "36/35 [==============================] - 30s 843ms/step - loss: 1.0736 - accuracy: 0.5995 - val_loss: 1.1674 - val_accuracy: 0.6107\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 1.01353\n",
      "Epoch 20/100\n",
      "36/35 [==============================] - 30s 842ms/step - loss: 1.0416 - accuracy: 0.6094 - val_loss: 1.4837 - val_accuracy: 0.5404\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.01353\n",
      "Epoch 21/100\n",
      "36/35 [==============================] - 32s 884ms/step - loss: 1.0038 - accuracy: 0.6302 - val_loss: 0.8888 - val_accuracy: 0.5995\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.01353 to 0.88884, saving model to model.hdf5\n",
      "Epoch 22/100\n",
      "36/35 [==============================] - 29s 819ms/step - loss: 1.0251 - accuracy: 0.6195 - val_loss: 1.3884 - val_accuracy: 0.5794\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.88884\n",
      "Epoch 23/100\n",
      " 3/35 [=>............................] - ETA: 23s - loss: 0.9590 - accuracy: 0.6198"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b2d663727b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(train_generator,steps_per_epoch=2250/64,\n\u001b[1;32m      2\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                               epochs=100, callbacks=[checkpointer, reduceLR, earlystopping])\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=2250/64,\n",
    "                              validation_data=test_generator,validation_steps=750/64, \n",
    "                              epochs=100, callbacks=[checkpointer, reduceLR, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('food_git_hub.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
