{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용 데이터 목록 : 계란찜, 과메기, 김치찌개, 미역줄기 볶음, 백김치  \n",
    "전처리 과정 : 없음  \n",
    "갯수 : 각 약 1000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.python.client import device_lib\n",
    "# # from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우가 인식하는 디바이스 중에 GPU가 있는지 확인\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , Activation, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with K.tf.device('gpu:0'):\n",
    "    model = Sequential([\n",
    "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150 ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(16, 3, padding='same', activation='relu', input_shape=(150, 150 ,3)),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "keras.preprocessing.image.ImageDataGenerator(featurewise_center=False, \n",
    "                                             samplewise_center=False, \n",
    "                                             featurewise_std_normalization=False, \n",
    "                                             samplewise_std_normalization=False, \n",
    "                                             zca_whitening=False, \n",
    "                                             zca_epsilon=1e-06, \n",
    "                                             rotation_range=0, \n",
    "                                             width_shift_range=0.0, \n",
    "                                             height_shift_range=0.0, \n",
    "                                             brightness_range=None, \n",
    "                                             shear_range=0.0, \n",
    "                                             zoom_range=0.0, \n",
    "                                             channel_shift_range=0.0, \n",
    "                                             fill_mode='nearest', \n",
    "                                             cval=0.0, \n",
    "                                             horizontal_flip=False, \n",
    "                                             vertical_flip=False, \n",
    "                                             rescale=None, \n",
    "                                             preprocessing_function=None, \n",
    "                                             data_format=None, \n",
    "                                             validation_split=0.0, dtype=None)\n",
    "'''\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=40, \n",
    "                                  zoom_range=0.8,\n",
    "                                   width_shift_range=0.5, \n",
    "                                  height_shift_range=0.5, \n",
    "                                  #batch_size=30,\n",
    "                                  )\n",
    "'''\n",
    "train_datagen = image_dataset_from_directory(rescale=1./255,rotation_range=40, \n",
    "                                  zoom_range=0.8,\n",
    "                                   width_shift_range=0.5, \n",
    "                                  height_shift_range=0.5, \n",
    "                                  batch_size=30,\n",
    "                                  )\n",
    "'''\n",
    "# test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 610 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # 타겟 디렉토리\n",
    "         target_size=(150, 150),  # 모든 이미지의 크기가 150x150로 조정\n",
    "        batch_size=30,\n",
    "        #rescale=1./255,\n",
    "        #rotation_range=40, \n",
    "      #zoom_range=0.8,\n",
    "       #width_shift_range=0.5, \n",
    "      #height_shift_range=0.5, \n",
    "        class_mode='binary')  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datagen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0dfc0f59e76a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;34m'data/train'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 타겟 디렉토리\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 모든 이미지의 크기가 150x150로 조정\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_datagen' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# validation_generator = test_datagen.flow_from_directory(\n",
    "#         'data/test',\n",
    "#         target_size=image_size,\n",
    "#         batch_size=batch_size,\n",
    "#         class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/50\n",
      "  4/100 [>.............................] - ETA: 1:09 - loss: -40.8621 - accuracy: 0.0500"
     ]
    }
   ],
   "source": [
    "hist=model.fit_generator(\n",
    "train_generator,\n",
    "steps_per_epoch=1000//batch_size,\n",
    "#validation_data=validation_generator,\n",
    "epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "결과가 나왔는데 비교 불가능이면 어떡하지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
