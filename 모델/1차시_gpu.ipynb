{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcMPTKCKnyGL"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wfLX32dwpKJ"
   },
   "source": [
    "# 1차시 \n",
    "\n",
    "이미지 크기 변경 : 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aq2a0UXDqSVj"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDQKBauKmjKJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wjMXLxkmS6Z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications import Xception\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3TlM4l5vTy1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "#from mlxtend.preprocessing import minmax_scaling\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input, BatchNormalization, Multiply, Activation\n",
    "from keras.optimizers import RMSprop, SGD\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N5WAtkdLw8s8"
   },
   "outputs": [],
   "source": [
    "# 변수 \n",
    "model_name = \"test_1\"\n",
    "model_save = f'{model_name}.hdf5'\n",
    "\n",
    "PATH=\"/content/drive/My Drive/Colab Notebooks/data\"\n",
    "img_size = 128 \n",
    "batch_size = 64\n",
    "\n",
    "calsses_num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sn38ueRBwYYc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1/255, validation_split=0.33)\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                 samplewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 samplewise_std_normalization=False,\n",
    "                 zca_whitening=False,\n",
    "                 rotation_range=5,\n",
    "                 width_shift_range=0.05,\n",
    "                 height_shift_range=0.05,\n",
    "                 shear_range=0.2,\n",
    "                 zoom_range=0.2,\n",
    "                 channel_shift_range=0.,\n",
    "                 fill_mode='nearest',\n",
    "                 cval=0.,\n",
    "                 horizontal_flip=True,\n",
    "                 vertical_flip=False,\n",
    "                 rescale=1/255,\n",
    "                validation_split=0.33\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZRkQYD5u5Ha"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "        seed=13,\n",
    "        target_size=(img_size,img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        subset=\"training\")\n",
    "\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "        seed=13, \n",
    "        target_size=(img_size,img_size), \n",
    "        batch_size=batch_size,\n",
    "        class_mode = 'categorical',\n",
    "        subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-WjCWs4vTwT"
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters = 256, kernel_size = (5,5), strides = 2, padding = 'Same', activation ='relu', input_shape = (img_size,img_size,3), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (5,5), strides = 2, padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (2,2),padding = 'Same', activation ='relu',kernel_initializer='he_normal'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation = \"relu\",kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(128, activation = \"relu\",kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(calsses_num, activation = \"softmax\",kernel_initializer='he_normal',kernel_regularizer=l2()))\n",
    "    model.summary()\n",
    "\n",
    "    #callbacks\n",
    "    checkpointer = ModelCheckpoint(filepath=model_save, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=20, mode='auto')\n",
    "    reduceLR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, mode='auto')\n",
    "    # stpes_per_epoch = 2250/64\n",
    "\n",
    "\n",
    "    model.compile(optimizer = 'Adam' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FDTyYwefvOak"
   },
   "outputs": [],
   "source": [
    "    # opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    # model.compile(optimizer = opt , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    # model.compile(optimizer = 'rmsprop' , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IPfRd_rLh47q"
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    history = model.fit_generator(train_generator,steps_per_epoch=100,\n",
    "                            validation_data=val_generator,validation_steps=100, \n",
    "                            epochs=100 ,workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJQ370G6h4vk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8CJkk3CvOV8"
   },
   "outputs": [],
   "source": [
    "    #testing phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_K-KH9hKlSQD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1차시.ipynb의 사본",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
