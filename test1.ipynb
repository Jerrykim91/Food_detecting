{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os , datetime , glob\n",
    "\n",
    "import cv2 \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-64156d691fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.preprocessing.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.abspath('./data/찌개/')\n",
    "data_label = list()\n",
    "data_list = list()\n",
    "for dirpath, dirnames, filenames  in os.walk(dir_path):\n",
    "    \n",
    "    data_label.append(dirnames)\n",
    "    data_list.append(filenames)\n",
    "#     print(dirnames )\n",
    "#     print(filenames, len(filenames))\n",
    "#     if filenames != len(filenames):\n",
    "#         print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Food_detecting\\\\data\\\\찌개'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김치찌개', '동태찌개', '된장찌개', '순두부찌개']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_label = data_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Img_121_0000.jpg',\n",
       "  'Img_121_0001.jpg',\n",
       "  'Img_121_0002.jpg',\n",
       "  'Img_121_0003.jpg',\n",
       "  'Img_121_0004.jpg',\n",
       "  'Img_121_0005.jpg',\n",
       "  'Img_121_0006.jpg',\n",
       "  'Img_121_0007.jpg',\n",
       "  'Img_121_0008.jpg',\n",
       "  'Img_121_0009.jpg',\n",
       "  'Img_121_0010.jpg'],\n",
       " ['Img_121_0000.jpg',\n",
       "  'Img_121_0001.jpg',\n",
       "  'Img_121_0002.jpg',\n",
       "  'Img_121_0003.jpg',\n",
       "  'Img_121_0004.jpg',\n",
       "  'Img_121_0005.jpg',\n",
       "  'Img_121_0006.jpg',\n",
       "  'Img_121_0007.jpg',\n",
       "  'Img_121_0008.jpg',\n",
       "  'Img_121_0009.jpg',\n",
       "  'Img_121_0010.jpg'],\n",
       " ['Img_123_0000.jpg',\n",
       "  'Img_123_0001.jpg',\n",
       "  'Img_123_0002.JPG',\n",
       "  'Img_123_0003.jpg',\n",
       "  'Img_123_0004.JPG',\n",
       "  'Img_123_0005.JPG',\n",
       "  'Img_123_0006.jpg',\n",
       "  'Img_123_0007.jpg',\n",
       "  'Img_123_0008.JPG',\n",
       "  'Img_123_0009.JPG',\n",
       "  'Img_123_0010.jpg']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = data_list[1:]\n",
    "data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode=`nearest`)\n",
    "\n",
    "img = load_img(`data/train/cats/cat.0.jpg`)  # PIL 이미지\n",
    "x = img_to_array(img)  # (3, 150, 150) 크기의 NumPy 배열\n",
    "x = x.reshape((1,) + x.shape)  # (1, 3, 150, 150) 크기의 NumPy 배열\n",
    "\n",
    "# 아래 .flow() 함수는 임의 변환된 이미지를 배치 단위로 생성해서\n",
    "# 지정된 `preview/` 폴더에 저장합니다.\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir=`preview`, save_prefix=`cat`, save_format=`jpeg`):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break  # 이미지 20장을 생성하고 마칩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())  # 이전 CNN 레이어에서 나온 3차원 배열은 1차원으로 뽑아줍니다\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# 학습 이미지에 적용한 augmentation 인자를 지정해줍니다.\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# 검증 및 테스트 이미지는 augmentation을 적용하지 않습니다. 모델 성능을 평가할 때에는 이미지 원본을 사용합니다.\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        `data/train`,  # this is the target directory\n",
    "        target_size=(150, 150),  # 모든 이미지의 크기가 150x150로 조정됩니다.\n",
    "        batch_size=batch_size,\n",
    "        class_mode=`binary`)  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        `data/validation`,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=`binary`)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        `data/validation`,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=`binary`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000 // batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=50)\n",
    "model.save_weights(`first_try.h5`)  # 많은 시간을 들여 학습한 모델인 만큼, 학습 후에는 꼭 모델을 저장해줍시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        `data/train`,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  #  라벨은 불러오지 않습니다.\n",
    "        shuffle=False)  # 출력되는 병목 특징이 어디서 왔는지 알 수 있도록 입력 데이터의 순서를 유지합니다 (사전순으로 cat 1000장, dog 1000장 순서로 입력이 들어옵니다).\n",
    "\n",
    "# 이미지를 모델에 입력시켜 결과를 가져옵니다. 본래 어떤 예측 결과가 출력되어야 하지만 모델의 일부만 가져왔기 때문에 병목 특징이 출력됩니다.\n",
    "bottleneck_features_train = model.predict_generator(generator, 2000)\n",
    "# 출력된 병목 데이터를 저장합니다.\n",
    "np.save(open(`bottleneck_features_train.npy`, `w`), bottleneck_features_train)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        `data/validation`,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 800)\n",
    "np.save(open(`bottleneck_features_validation.npy`, `w`), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(open(`bottleneck_features_train.npy`))\n",
    "# 앞서 언급한 바와 같이 병목 특징은 순서대로 추출되기 때문에 라벨 데이터는 아래와 같이 손쉽게 생성할 수 있습니다.\n",
    "train_labels = np.array([0] * 1000 + [1] * 1000)\n",
    "\n",
    "validation_data = np.load(open(`bottleneck_features_validation.npy`))\n",
    "validation_labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation=`relu`))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=`sigmoid`))\n",
    "\n",
    "model.compile(optimizer=`rmsprop`,\n",
    "              loss=`binary_crossentropy`,\n",
    "              metrics=[`accuracy`])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights(`bottleneck_fc_model.h5`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최상단 레이어를 생성합니다\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation=`relu`))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation=`sigmoid`))\n",
    "\n",
    "# 기존 네트워크와 마찬가지로 이 방식에서는 최상단 레이어도 미리 학습되어 있어야 합니다.\n",
    "# 앞서 학습시킨 가중치를 불러옵니다.\n",
    "\n",
    "# VGG convolution 기반 위에 최상단 레이어를 얹습니다.\n",
    "model.add(top_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
