{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  전이학습 기반 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# a = np.array([[1,2,3],[1,2,3],[1,2,3]])\n",
    "# img = Image.fromarray(a)\n",
    "# b = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qpwpUhVod2ob"
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import rand\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cnn_utils as utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1669,
     "status": "ok",
     "timestamp": 1531341784750,
     "user": {
      "displayName": "Raghav Bali",
      "photoUrl": "//lh4.googleusercontent.com/-HPass-4Bl9U/AAAAAAAAAAI/AAAAAAAAKiI/A0BQ8MHwVME/s50-c-k-no/photo.jpg",
      "userId": "117317575176939780509"
     },
     "user_tz": -330
    },
    "id": "VB1artr2KuLD",
    "outputId": "295301d0-a703-4793-fbc9-74c200f15189"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import callbacks, optimizers,Model\n",
    "from tensorflow.keras.applications import vgg16 as vgg\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 세트 로딩과 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fS8uGXn5dgRU"
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 50    # 기본: 100\n",
    "# NUM_CLASSES = 10 # 카테고리수 \n",
    "# LEARNING_RATE = 1e-4\n",
    "# MOMENTUM = 0.9\n",
    "# PATH=r\"C:\\Users\\admin\\Desktop\\image\\#5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 40    # 기본: 100\n",
    "NUM_CLASSES = 8 # 카테고리수 \n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9\n",
    "PATH=r\"C:\\Users\\admin\\Desktop\\image\\#3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PoT9P1phLuyT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "base_model = vgg.VGG16(weights='imagenet', \n",
    "                       include_top=False, \n",
    "                       input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "khNrl8nHqesu"
   },
   "outputs": [],
   "source": [
    "# VGG16 모델의 세 번째 블록에서 마지막 층 추출\n",
    "# VGG16 모델의 네 번째 블록에서 마지막 층 추출\n",
    "last = base_model.get_layer('block4_pool').output\n",
    "# last = base_model.get_layer('block3_pool').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 준비\n",
    "\n",
    "* 최상위층 없이 VGG16 로딩\n",
    "* 커스텀 분류기 준비\n",
    "* 모델의 맨 위에 새로운 층 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MI90lh6hL9ua"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 7,836,488\n",
      "Trainable params: 7,835,464\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 상위 층에 분류층 추가\n",
    "x = GlobalAveragePooling2D()(last)\n",
    "x= BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.7)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.6)(x)\n",
    "pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(base_model.input, pred)\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint('model_cnn_#3-{epoch:03d}-{acc:03f}-{val_acc:03f}.h5', verbose=1,\n",
    "                                             monitor='val_loss',\n",
    "                                             save_best_only=True, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fc3EhfLTMD4I"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "PRXPI3DCMIIK"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1531341814064,
     "user": {
      "displayName": "Raghav Bali",
      "photoUrl": "//lh4.googleusercontent.com/-HPass-4Bl9U/AAAAAAAAAAI/AAAAAAAAKiI/A0BQ8MHwVME/s50-c-k-no/photo.jpg",
      "userId": "117317575176939780509"
     },
     "user_tz": -330
    },
    "id": "PATZIBLlMLrf",
    "outputId": "f9a4ac68-9261-46d8-a7c9-9e15cfcf5631"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                 rescale=1/255,\n",
    "                validation_split=0.33\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_Y-jNseQMNcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3905 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "        seed=13,\n",
    "        target_size=(128,128),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode = 'categorical',\n",
    "        subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mHPmLOf-N3SQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1918 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_directory(\n",
    "        PATH,\n",
    "        shuffle=True,\n",
    "        seed=13,\n",
    "        target_size=(128,128),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode = 'categorical',\n",
    "        subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JSIJycdbrBWK",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4887 - acc: 0.8411Epoch 1/40\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.3373 - acc: 0.8751\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.33735, saving model to model_cnn_#3-001-0.841210-0.875059.h5\n",
      "100/100 [==============================] - 451s 5s/step - loss: 0.4886 - acc: 0.8412 - val_loss: 0.3373 - val_acc: 0.8751\n",
      "Epoch 2/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4484 - acc: 0.8481Epoch 1/40\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.3241 - acc: 0.8753\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.33735 to 0.32410, saving model to model_cnn_#3-002-0.848351-0.875313.h5\n",
      "100/100 [==============================] - 453s 5s/step - loss: 0.4476 - acc: 0.8484 - val_loss: 0.3241 - val_acc: 0.8753\n",
      "Epoch 3/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.4198 - acc: 0.8550Epoch 1/40\n",
      "100/100 [==============================] - 228s 2s/step - loss: 0.3146 - acc: 0.8761\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.32410 to 0.31457, saving model to model_cnn_#3-003-0.854998-0.876114.h5\n",
      "100/100 [==============================] - 452s 5s/step - loss: 0.4200 - acc: 0.8550 - val_loss: 0.3146 - val_acc: 0.8761\n",
      "Epoch 4/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.3973 - acc: 0.8594Epoch 1/40\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.3088 - acc: 0.8771\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31457 to 0.30877, saving model to model_cnn_#3-004-0.859423-0.877131.h5\n",
      "100/100 [==============================] - 448s 4s/step - loss: 0.3970 - acc: 0.8594 - val_loss: 0.3088 - val_acc: 0.8771\n",
      "Epoch 5/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.3797 - acc: 0.8643Epoch 1/40\n",
      "100/100 [==============================] - 229s 2s/step - loss: 0.3030 - acc: 0.8781\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30877 to 0.30303, saving model to model_cnn_#3-005-0.864467-0.878089.h5\n",
      "100/100 [==============================] - 452s 5s/step - loss: 0.3791 - acc: 0.8645 - val_loss: 0.3030 - val_acc: 0.8781\n",
      "Epoch 6/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.3643 - acc: 0.8684Epoch 1/40\n",
      "100/100 [==============================] - 240s 2s/step - loss: 0.2984 - acc: 0.8790\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.30303 to 0.29841, saving model to model_cnn_#3-006-0.868431-0.879047.h5\n",
      "100/100 [==============================] - 464s 5s/step - loss: 0.3641 - acc: 0.8684 - val_loss: 0.2984 - val_acc: 0.8790\n",
      "Epoch 7/40\n",
      " 99/100 [============================>.] - ETA: 2s - loss: 0.3485 - acc: 0.8702Epoch 1/40\n",
      "100/100 [==============================] - 232s 2s/step - loss: 0.2922 - acc: 0.8807\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.29841 to 0.29223, saving model to model_cnn_#3-007-0.870238-0.880748.h5\n",
      "100/100 [==============================] - 457s 5s/step - loss: 0.3487 - acc: 0.8702 - val_loss: 0.2922 - val_acc: 0.8807\n",
      "Epoch 8/40\n",
      " 21/100 [=====>........................] - ETA: 2:59 - loss: 0.3465 - acc: 0.8703"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-577357f76adb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_steps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                               verbose=1, callbacks=[checkpoint,csv_logger])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_steps_per_epoch =100\n",
    "val_steps_per_epoch = 100\n",
    "path_csv = 'log_#3.csv'\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger(f'./{path_csv}', append=True, separator=';')\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS,\n",
    "                              verbose=1, callbacks=[checkpoint,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.savefig('VGG16_#3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 50    # 기본: 100\n",
    "# NUM_CLASSES = 8 # 카테고리수 \n",
    "# LEARNING_RATE = 1e-4\n",
    "# MOMENTUM = 0.9\n",
    "# PATH=r\"C:\\Users\\admin\\Desktop\\image\\#3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphviz\n",
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./vgg16_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('vgg16.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Copy of cifar10_vgg16_july12.ipynb",
   "provenance": [
    {
     "file_id": "1tlQq2thZWPDNqaMbfBJ9_TOo0YTqv7IL",
     "timestamp": 1531320536438
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
